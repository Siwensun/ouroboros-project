<!DOCTYPE html>
<html>
<head>

  <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-G56S7NBPZ0"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-G56S7NBPZ0');
</script>

  <meta charset="utf-8">
  <meta name="description"
        content="Ouroboros: Single-step Diffusion Models for Cycle-consistent Forward and Inverse Rendering">
  <meta name="keywords" content="Diffusion, Neural Rendering">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Ouroboros: Single-step Diffusion Models for Cycle-consistent Forward and Inverse Rendering</title>


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/icon.png">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="publication-header">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Ouroboros: Single-step Diffusion Models for Cycle-consistent Forward and Inverse Rendering</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=c6wKvwgAAAAJ&hl=en">Shanlin Sun</a><sup>*</sup><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://yfwang.me/">Yifan Wang</a><sup>*</sup><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://github.com/zhw123456789/">Hanwen Zhang</a><sup>*</sup><sup>3</sup>,</span>
            <span class="author-block">
              <a href="https://yuukino22.github.io/">Yifeng Xiong</a><sup>1</sup></span></sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=Tcg-9DcAAAAJ&hl=zh-CN">Qin Ren</a><sup>2</sup></span> <br>
            <span class="author-block">
              <a href="https://lab-smile.github.io/">Ruogu Fang</a><sup>†</sup><sup>4</sup></span></sup>,</span>
            <span class="author-block">
              <a href="https://ics.uci.edu/~xhx/">Xiaohui Xie</a><sup>†</sup><sup>1</sup></span></sup>,</span>
            <span class="author-block">
              <a href="https://chenyuyou.me/">Chenyu You</a><sup>†</sup><sup>2</sup></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of California, Irvine </span> &nbsp &nbsp
            <span class="author-block"><sup>2</sup>Stony Brook University </span> <br>
            <span class="author-block"><sup>3</sup>Huazhong University of Science and Technology</span> &nbsp &nbsp
            <span class="author-block"><sup>4</sup>University of Florida</span> 
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/2212.09530"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/2405.00900"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=SA5xADW2eJ0&t=4s"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/korrawe/harp"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span> -->
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser", style="margin-top: -20px;">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <figure class="content has-text-centered">
        <img src="./static/images/teaser.png"
                 alt="Teaser image."
                />
      </figure>
      <!-- <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/images/teaser.mp4"
                type="video/mp4">
      </video> -->
      <h2 class="subtitle">
        <b> Single-step Diffusion Models for Forward and Inverse Rendering in Cycle Consistency </b>.<br>
        <b>Left Upper:</b> Ouroboros decomposes input images into intrinsic maps (albedo, normal, roughness, metallicity, and irradiance). 
        Given these generated intrinsic maps and textual prompts, our neural forward rendering model synthesizes images closely matching the originals.<br>
        <b>Right Upper:</b> We extend an end-to-end finetuning technique to diffusion-based neural rendering. The radar plot illustrates numerical comparisons with RGB↔X on the InteriorVerse dataset.<br>
        <b>Bottom:</b> Our method achieves temporally consistent video inverse rendering without specific finetuning on video data.
      </h2>
    </div>
  </div>
</section>

<!-- <section class="section"> -->
  <section class="hero is-light is-small">
    <div class="container is-max-desktop">
      <br>
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              While multi-step diffusion models have advanced both forward and inverse rendering, existing approaches often treat these problems independently, leading to cycle inconsistency and slow inference speed. 
              In this work, we present <b>Ouroboros</b>, a framework composed of two single-step diffusion models that handle forward and inverse rendering with mutual reinforcement. 
              Our approach extends intrinsic decomposition to both indoor and outdoor scenes and introduces a cycle consistency mechanism that ensures coherence between forward and inverse rendering outputs.
              Experimental results demonstrate state-of-the-art performance across diverse scenes while achieving substantially faster inference speed compared to other diffusion-based methods.
              We also demonstrate that Ouroboros can transfer to video decomposition in a training-free manner, reducing temporal inconsistency in video sequences while maintaining high-quality per-frame inverse rendering.
            </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->

      <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/SA5xADW2eJ0?si=xDg5Z3T9m9eJk3Ht"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
  <br/>
</section>
<!-- <iframe width="560" height="315" src="https://www.youtube.com/embed/heWXQdIjSzs?si=QDc62aFZW8uLj-e3" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe> -->



</body>
</html>